{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AfterWork Data Science: Classification Analysis with Python",
      "provenance": [],
      "collapsed_sections": [
        "BA_HMQbPHWQJ",
        "SPpfqZYzrKvs",
        "eagUqvVmeRTx",
        "Pz6qTiItChtg",
        "G8NJS6N6eU7j",
        "wBSYp3fVIupH",
        "uebT2koxr4V4",
        "B-eE6btO3KKM",
        "eiWteB6fHPmU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinGalacha/ApiSamples/blob/master/Copy_of_AfterWork_Data_Science_Classification_Analysis_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpeR9aETcRDP",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"blue\">To use this notebook on Google Colaboratory, you will need to make a copy of it. Go to **File** > **Save a Copy in Drive**. You can then use the new copy that will appear in the new tab.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e13tRpKcJHm",
        "colab_type": "text"
      },
      "source": [
        "# AfterWork Data Science: Classification Analysis with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_HMQbPHWQJ",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moay-lWZm7z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "719c8e74-b8d6-4381-a04b-545e4e041ab7"
      },
      "source": [
        "# We will start by running this cell which will import the necessary libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd                # Pandas for data manipulation\n",
        "import numpy as np                 # Numpy for scientific computations\n",
        "import matplotlib.pyplot as plt    # Matplotlib for visualisation - We might not use it but just incase you decide to \n",
        "%matplotlib inline                 # This line will store and show our visualisations"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: unrecognized arguments: # This line will store and show our visualisations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPpfqZYzrKvs",
        "colab_type": "text"
      },
      "source": [
        "## Example "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6pUHkWwrI8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example \n",
        "# ---\n",
        "# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n",
        "# ---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eagUqvVmeRTx",
        "colab_type": "text"
      },
      "source": [
        "#### Data Importation and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1pbsTYuPOLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c6bbb5a-422d-4453-ed60-b991296130a2"
      },
      "source": [
        "# Loading and previewing our dataset\n",
        "# ---\n",
        "# \n",
        "social_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset')\n",
        "social_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>Female</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510    Male   19            19000          0\n",
              "1  15810944    Male   35            20000          0\n",
              "2  15668575  Female   26            43000          0\n",
              "3  15603246  Female   27            57000          0\n",
              "4  15804002    Male   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZkxTRrdQaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e46ea273-11ee-47e2-fb70-4cf69d762d2e"
      },
      "source": [
        "# Determining the size of our dataset\n",
        "# (records, columns)\n",
        "# ---\n",
        "# \n",
        "social_df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz6qTiItChtg",
        "colab_type": "text"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtaBMmZBCkW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e4fd467a-e3fb-4aa7-e851-42787358abf7"
      },
      "source": [
        "# Normally during this stage we would perform quite a number of \n",
        "# procedures, but because our focus is only onlearning about the \n",
        "# different modeling algorithms, we will only perform once \n",
        "# essential step in ot dataset. We will perform encoding,\n",
        "# which will help us transform our categorical values in our \n",
        "# dataset into numerical values. \n",
        "# Lets see what happens when we encode the gender variable \n",
        "# to have only numerical values. \n",
        "# ---\n",
        "#\n",
        "social_df[\"Gender\"] = np.where(social_df[\"Gender\"].str.contains(\"Male\", \"Female\"), 1, 0)\n",
        "social_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510       1   19            19000          0\n",
              "1  15810944       1   35            20000          0\n",
              "2  15668575       0   26            43000          0\n",
              "3  15603246       0   27            57000          0\n",
              "4  15804002       1   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8NJS6N6eU7j",
        "colab_type": "text"
      },
      "source": [
        "#### Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybg1VYOGSXbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing our dataset for training\n",
        "# ---\n",
        "# We first divide our data into attributes and labels:\n",
        "# You can think of this as splitting our data set in dependent and independent variables \n",
        "# where Age and EstimatedSalary are the independent variables and Purchased are the dependent/label variable.\n",
        "# ---\n",
        "# \n",
        "X = social_df.iloc[:, [1, 2 ,3]].values  # Independent/predictor variables\n",
        "y = social_df.iloc[:, 4].values          # Dependent/label variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFyZcCeVScEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into a training set and test set\n",
        "# ---\n",
        "# We will split our dataset into training data and test data. \n",
        "# Training data will be used to train our logistic model and test data will be used to validate our model\n",
        "# Because we’ll use sklearn to split our data, we will import train_test_split from sklearn.model_selection\n",
        "# ---\n",
        "# \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgn73UwVS9hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling / Normalisation\n",
        "# ---\n",
        "# We then perform feature scaling / normalisation to scale our data between 0 and 1 so as to get better accuracy.\n",
        "# Here, scaling is important because there is a huge difference between Age and EstimatedSalary.\n",
        "# In addition, this would also reduce redundacy in our dataset. \n",
        "# ---\n",
        "# \n",
        "\n",
        "# We import our scaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# We make an instance sc_X of the object StandardScaler.\n",
        "# You can think of making an instance as making a copy.\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "# We then fit and transform X_train and X_test\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cDNlsiGTaRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43b735d4-173e-4835-85da-aa8039629621"
      },
      "source": [
        "# In this example, because we will be comparing how \n",
        "# the different classification algorithms will perform, \n",
        "# we import our classifiers as shown below.\n",
        "# ---\n",
        "#\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier     # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                         # SVM Classifier\n",
        "from sklearn.naive_bayes import GaussianNB          # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\n",
        "\n",
        "# Below, we make an instance classifier of the object LogisticRegression, \n",
        "# DecisionTreeClassifier, SVC, GaussianNB, KNeighborsClassifier, GaussianNB.\n",
        "# As we will get to see, each of the classifiers take different parameters.\n",
        "# ---\n",
        "# \n",
        "logistic_classifier = LogisticRegression(random_state = 0, solver='lbfgs')\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "naive_classifier = GaussianNB()\n",
        "\n",
        "# Now using these classifiers to fit our data, X_train and y_train.\n",
        "# By fitting we mean we train our classifiers based on the train dataset.\n",
        "# ---\n",
        "# Upon running this cell, we should have classifiers that can predict \n",
        "# whether a person will buy a car or not.\n",
        "# ---\n",
        "# Don't worry about the output, we get GaussianNB because our Naive Bayes classifier\n",
        "# is the last one to be built.\n",
        "# ---\n",
        "#\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAx-7zU7Tyrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We now predict the test set results. \n",
        "# This will help us determine whether our classifiers made the correct predictions.\n",
        "# ---\n",
        "# No expected output here.\n",
        "# ---\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG_q-tVaUFxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4ec5d83b-4815-40ee-996e-c1055334f7eb"
      },
      "source": [
        "# We then import evaluation metrics to determine the accuracy of classifiers\n",
        "# ---\n",
        "# \n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "\n",
        "# The accuracy score - is the simplest way to evaluate \n",
        "# However, we note not for a highly imbalance dataset. \n",
        "# By imbalanced we mean that our original dataset would\n",
        "# need to have an equal no's of 1 and 0's\n",
        "# ---\n",
        "print(accuracy_score(logistic_y_prediction, y_test))\n",
        "print(accuracy_score(decision_y_prediction, y_test))\n",
        "print(accuracy_score(svm_y_prediction, y_test))\n",
        "print(accuracy_score(knn_y_prediction, y_test))\n",
        "print(accuracy_score(naive_y_prediction, y_test))\n",
        "\n",
        "# From the accuracy scores we get 90%, 90%, 93%, 93% & 91% respectively.\n",
        "# The most accurate classifier being SVM & KNN. "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9\n",
            "0.9\n",
            "0.93\n",
            "0.93\n",
            "0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wgNdhhrdVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "d57ca323-24fc-4057-85ab-3c893d8ac5ff"
      },
      "source": [
        "# We now print the classification report, \n",
        "# which is more reliable for a highly imbalanced dataset. \n",
        "# We use the precision values which give us accuracy values.\n",
        "# \n",
        "# ---\n",
        "# The precision will be \"how many are correctly classified among that class\".\n",
        "# The recall means \"how many of this class you find over the whole number of element of this class\".\n",
        "# The f1-score is the harmonic mean between precision & recall.\n",
        "# The support is the number of occurence of the given class in your dataset.\n",
        "# ---\n",
        "# \n",
        "print('Logistic classifier:')\n",
        "print(classification_report(y_test, logistic_y_prediction))\n",
        "\n",
        "print('Decision Tree classifier:')\n",
        "print(classification_report(y_test, decision_y_prediction))\n",
        "\n",
        "print('SVM Classifier:')\n",
        "print(classification_report(y_test, svm_y_prediction))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(classification_report(y_test, knn_y_prediction))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(classification_report(y_test, naive_y_prediction)) \n",
        "\n",
        "# From our classification report,\n",
        "# Our support tells us that our dataset is highly imbalanced i.e. 63 0's and 32 1's.\n",
        "# From the weighted avg which takes into account of our imbalanced\n",
        "# dataset we get 90%, 90%, 93%, 93%, 91%.\n",
        "# Still, the most accurate classifiers being SVM and KNN. \n",
        "# We can then further perform model opmization techiniques i.e. \n",
        "# data cleaning, feature engineering, checking for model assumptions, etc. \n",
        "# to further get the best classifier. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93        68\n",
            "           1       0.89      0.78      0.83        32\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.90      0.87      0.88       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n",
            "Decision Tree classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        68\n",
            "           1       0.84      0.84      0.84        32\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.89      0.89      0.89       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n",
            "SVM Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        68\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.92      0.92      0.92       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n",
            "KNN Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        68\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.92      0.92      0.92       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n",
            "Naive Bayes Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94        68\n",
            "           1       0.93      0.78      0.85        32\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.92      0.88      0.89       100\n",
            "weighted avg       0.91      0.91      0.91       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnqqUOET9QLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0aec6dcc-dfd2-4a98-f6bc-02372246a6ba"
      },
      "source": [
        "# Answering our question\n",
        "# ---\n",
        "# We then make a new prediction & compare results.\n",
        "# Note that we would only use the best optimized classifier for this case.\n",
        "# ---\n",
        "# Predict whether John, 60 years old with a salary of 2500 will buy a car or not?\n",
        "# ---\n",
        "# Dataset limitation: This is not a practical dataset, thus dataset will lack essential features/variables.\n",
        "# In a real case scenario, we would work with may kinds of datasets that require transformation\n",
        "# i.e. data cleaning, feature engineering, etc.\n",
        "# ---\n",
        "#\n",
        "new_case = [[1,\t60, 1500]]\n",
        "\n",
        "print(logistic_classifier.predict(new_case))\n",
        "print(decision_classifier.predict(new_case))\n",
        "print(\"Best Classifier SVM\", svm_classifier.predict(new_case))\n",
        "print(\"Best Classifier KNN\", knn_classifier.predict(new_case))\n",
        "print(naive_classifier.predict(new_case))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[1]\n",
            "Best Classifier SVM [1]\n",
            "Best Classifier KNN [1]\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBSYp3fVIupH",
        "colab_type": "text"
      },
      "source": [
        "##<font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebT2koxr4V4",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcDuh88sFLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: As a Reseacher at KEMRI you are performing research on diabetes.\n",
        "# Create the a classifier to determine whether a person has diabetes or not\n",
        "# from the given the following sample dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/ADiabetesDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-eE6btO3KKM",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Q2CMI2wg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: A cancer medical reasearch institution would like to make predictions on two different \n",
        "# cancer types benign and malignant. Build a model to predict the breast cancer type \n",
        "# (0 = benign or 1 = malignant) given the following dataset. In addition, make a prediction.\n",
        "# NB: Remember to record your observations.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/BreastCancersDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiWteB6fHPmU",
        "colab_type": "text"
      },
      "source": [
        "###<font color=\"green\">Challenge 3</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZ25wbCHQPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Build a classifier to predict car sales and check the accuracy of the prediction.\n",
        "# given the following dataset\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/3dvU2BB\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}